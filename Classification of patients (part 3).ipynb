{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a8760f4-3c3b-4456-a107-32160590c78c",
   "metadata": {},
   "source": [
    "# About the project\n",
    "The end goal of this project is to classify patients with high protein concentration in urine and the healthy group based on SERS (Surface Enchanced Raman Spectroscopy) spectral data and biomedical data.  \n",
    "This project is to be released as a research paper later in 2022 or 2023. Some information might not be fully shown here as a result.\n",
    "\n",
    "The project is divided into several Jupyter notebooks with the following names:\n",
    "1) Import raw urine spectra (part 1)\n",
    "2) Spectra processing (part 2)\n",
    "3) Classification of patients (part 3)\n",
    "4) Biomedical data (part 4)\n",
    "5) Comparison of nanoparticles (part 5)\n",
    "\n",
    "Author of all codes: Sultan Aitekenov, sultanaitekenov@gmail.com\n",
    "\n",
    "Part of the upcoming abstract:\n",
    "Excessive protein excretion in human urine is an early and sensitive marker of diabetic nephropathy, primary and secondary renal disease. Kidney problems, particularly chronic kidney disease, remain among the few growing causes of mortality in the world. Therefore, it is important to develop efficient, expressive, and low-cost method for protein determination. Surface enhanced Raman spectroscopy (SERS) methods are potential candidates to achieve those criteria. In this paper, the SERS methods was developed to distinguish patients with proteinuria and the healthy group. Commercial gold nanoparticles with the diameter of 60 nm and 100 nm, and silver nanoparticles with the diameter of 100 nm were employed. Silver, gold, silicon and test slides covered with aluminium tape were utilized as substrates. Obtained spectra were analysed with several machine learning algorithms coupled with the PCA, ROC curve, and cross-validation methods. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd88270c-13b2-4ce5-9ea6-66837b763d5f",
   "metadata": {},
   "source": [
    "# Classification of patients (part 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd91562e",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d9648c-03da-49f8-8670-23afd99edc97",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be1a742-8f70-4061-bb4b-a20df76751f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other modules related to classification are imported later\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c1757-6536-48e2-a3f7-fd4c30364365",
   "metadata": {},
   "source": [
    "### Raman Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92678639-f128-400c-b32f-daefb3df9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si_60nm_AuNPs is not included though\n",
    "raman_shift_400_1800=np.array(pd.read_csv('raman_shift_400_1800.csv', header=None))\n",
    "raman_shift_600_1800=np.array(pd.read_csv('raman_shift_600_1800.csv', header=None))\n",
    "wave = raman_shift_400_1800[0]\n",
    "wave_Si = raman_shift_600_1800[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea487e-161d-4546-82aa-fd06e28c3c12",
   "metadata": {},
   "source": [
    "### Processed urine spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data contains a nested dictionary\n",
    "f = open('processed_urine_spectra.pkl', 'rb')\n",
    "processed_urine_spectra = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0e026-0ee5-4e00-8465-b0e104ac07ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_urine_spectra.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72001f5e-14a6-4780-99cd-302caac04d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete 'Au_40nm_AuNPs' as it was not used for classification, see part 5\n",
    "del processed_urine_spectra['Au_40nm_AuNPs']\n",
    "del processed_urine_spectra['Au_no_AuNPs']\n",
    "del processed_urine_spectra['Au_HSA_AuNPs']\n",
    "del processed_urine_spectra['glass_no_AuNPs']\n",
    "del processed_urine_spectra['Si_no_AuNPs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8fedf9-be81-43ec-beb3-2176422ca70c",
   "metadata": {},
   "source": [
    "### Protein data and health status\n",
    "Both protein data and health status will be used for labelling. They do not coincide with each other. To get more information about biomedical data see Part 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43348b6-9d57-4e52-b213-bdbab9cbc081",
   "metadata": {},
   "source": [
    "#### Protein data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff49c50f-1228-401c-82bf-00862165efef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# protein data\n",
    "bio_data = pd.read_csv('urine biomedicals processed.csv')\n",
    "bio_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041b55fa-d228-4175-a5d5-db283ead381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert info_protein to dictionary with keys being equal to patients' ID for all patients in the database \n",
    "info_protein={}\n",
    "for i in range(0,len(bio_data)):\n",
    "    key_ID = bio_data['patient_ID'][i]\n",
    "    info_protein[key_ID] = float(bio_data['Protein, mg/L'][i]) #converts to mg/L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43b38a-ff6a-4785-a3e2-48cb2833fbf3",
   "metadata": {},
   "source": [
    "#### Health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489840c2-87cf-4745-a8e3-799d2ddc5d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026138c6-9263-48c4-8fb0-9b4683bff0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bio_data['status'] == 'diseased').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6281faf2-0e61-457d-a83e-cb3c16987290",
   "metadata": {},
   "outputs": [],
   "source": [
    "(bio_data['status'] == 'healthy').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c8e2a8-037d-4d76-995e-5a11a5a3e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bio_data['status'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578e3381-03ca-449b-a011-b869b2ce1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# health status\n",
    "health_status={}\n",
    "for i in range(0,len(bio_data)):\n",
    "    key_ID = bio_data['patient_ID'][i]\n",
    "    if bio_data['status'][i] == 1:\n",
    "        health_status[key_ID] = 1\n",
    "    elif bio_data['status'][i] == 0:\n",
    "        health_status[key_ID] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb5b05bf-3edc-4328-ba77-9889264f1271",
   "metadata": {},
   "source": [
    "# health status\n",
    "health_status={}\n",
    "for i in range(0,len(bio_data)):\n",
    "    key_ID = bio_data['patient_ID'][i]\n",
    "    if bio_data['Protein to creatinine'][i] == 1:\n",
    "        health_status[key_ID] = 1\n",
    "    elif bio_data['Protein to creatinine'][i] == 0:\n",
    "        health_status[key_ID] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f19630-1484-46fc-9982-a84528b23e49",
   "metadata": {},
   "source": [
    "## Assign patients to high or low protein group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0e7342-cb98-4ffe-befe-e1c20b26b7de",
   "metadata": {},
   "source": [
    "### Define function that assigns to high and low protein concentration groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6437666e-c803-48d5-a76a-4e416fdeb638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function for creation of groups, the same structure as spectra data\n",
    "def raman_protein_info(input_spectra, input_protein, protein_threshold):\n",
    "    \"\"\"\n",
    "    Compares samples with database. Returns error if match is not found for\n",
    "    samples. Reports which samples were not included.\n",
    "    low protein == 0\n",
    "    high protein == 1\n",
    "    protein threshold in mg/L\n",
    "    \n",
    "    Output file has the same structure as input_spectra\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    \n",
    "    # copies the same structure as input spectra\n",
    "    output_group = copy.deepcopy(input_spectra)\n",
    "    \n",
    "    # cycle through expiremntal sets\n",
    "    for key_set in input_spectra.keys():\n",
    "        # cycles through patients with key_ID\n",
    "        for key_ID in input_spectra[key_set].keys():\n",
    "            # take protein gramm from input_protein\n",
    "            protein_gramm = input_protein.get(key_ID)\n",
    "            if protein_gramm == None:\n",
    "                print(f\"error - your protein gramm value is not found in the database for patient {key_ID} in {key_set}\")\n",
    "                # delete patients who is not in the protein database\n",
    "                output_group[key_set][key_ID] = None\n",
    "                # del input_spectra[key_set][key_ID]\n",
    "            elif protein_gramm >= protein_threshold:\n",
    "                output_group[key_set][key_ID] = 1\n",
    "            elif protein_gramm <= protein_threshold:\n",
    "                output_group[key_set][key_ID] = 0\n",
    "    \n",
    "    \n",
    "    output_group_final = output_group\n",
    "    return output_group_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94a402f-aa23-434b-8812-11be589dd3e6",
   "metadata": {},
   "source": [
    "### For each experimental set assign to protein groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b434f73-5c14-41fe-8a80-8c546a8ebd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein is set to 300 mg/L as it is important threshold for medical diagnostics\n",
    "protein_threshold =  300\n",
    "groups_protein = raman_protein_info(processed_urine_spectra, info_protein, protein_threshold)\n",
    "groups_protein;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad93323-a6e2-4abd-a1bb-30c7ff0e4ef8",
   "metadata": {},
   "source": [
    "### Define function that assigns according to the health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a384c1c-b2d9-432e-8ad8-22d1823a2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raman_health_info(input_spectra, health_status):\n",
    "    \"\"\"\n",
    "    Compares samples with database according to their health status.\n",
    "    diseased == 1\n",
    "    healthy == 0\n",
    "\n",
    "    Output file has the same structure as input_spectra\n",
    "    \"\"\"\n",
    "    import copy\n",
    "    \n",
    "    # copies the same structure as input spectra\n",
    "    output_group = copy.deepcopy(input_spectra)\n",
    "    \n",
    "    # cycle through expiremntal sets\n",
    "    for key_set in input_spectra.keys():\n",
    "        # cycles through patients with key_ID\n",
    "        for key_ID in input_spectra[key_set].keys():\n",
    "            \n",
    "            output_group[key_set][key_ID] = health_status.get(key_ID)\n",
    "\n",
    "    return output_group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00944d1a-0e48-4bec-a6f7-3813aca1d02b",
   "metadata": {},
   "source": [
    "### For each experimental set assign to health status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42877615-e313-4194-9083-9975f8e7619d",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_health = raman_health_info(processed_urine_spectra, health_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dc6bd8-9fd9-4935-a7ee-39ba286b9b5d",
   "metadata": {},
   "source": [
    "## Prepare data for x and y training sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12707833-3890-4d50-913c-62cd96b9cd71",
   "metadata": {},
   "source": [
    "### Select a limited range in raman shift, as it might help to improve classification scores. Uncomment or change status of the cells to Code."
   ]
  },
  {
   "cell_type": "raw",
   "id": "593e0467-1efd-4511-b75f-724c96923940",
   "metadata": {},
   "source": [
    "# select range for Raman Shift\n",
    "wave_left = 1060\n",
    "wave_right = 1800\n",
    "# create boolean array and apply it to wave\n",
    "select_range = (wave_left <= wave) & (wave <= wave_right)\n",
    "wave = wave[select_range]\n",
    "# output\n",
    "print(len(select_range))\n",
    "wave"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2427d1fa-2fd4-4d8f-a6a8-5709fb846e6f",
   "metadata": {},
   "source": [
    "# loop over experimental sets except for the set Si_60_AuNPs as it contains different data\n",
    "for key_set in processed_urine_spectra.keys():\n",
    "    if key_set != 'Si_60nm_AuNPs' and key_set != 'Si_3x_100nm_AuNPs':\n",
    "        #loop over patients' IDs\n",
    "        for key_ID in processed_urine_spectra[key_set].keys():\n",
    "            spectrum = processed_urine_spectra[key_set][key_ID]\n",
    "            limited_spectrum = spectrum[select_range]\n",
    "            processed_urine_spectra[key_set][key_ID] = []\n",
    "            processed_urine_spectra[key_set][key_ID] = limited_spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057635d5-b8cd-40bd-aaf4-34afe8f3401b",
   "metadata": {},
   "source": [
    "### Convert dictionaries to matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b971d6ec-068f-4b13-a40b-8e5581734353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dict\n",
    "x = {}\n",
    "y = {}\n",
    "IDs = {}\n",
    "\n",
    "\n",
    "for key_set in processed_urine_spectra.keys():\n",
    "        # create empty matrix to assign to them values later\n",
    "        matrix_x = []\n",
    "        matrix_y = []\n",
    "        matrix_IDs = []\n",
    "        \n",
    "        # loop to make dict into matrix\n",
    "        for key_ID in processed_urine_spectra[key_set].keys():                                                      \n",
    "            matrix_x.append( processed_urine_spectra[key_set][key_ID] )\n",
    "            # matrix_y.append( groups_health[key_set][key_ID] )\n",
    "            matrix_y.append( groups_protein[key_set][key_ID] )\n",
    "            matrix_IDs.append( int(key_ID) )\n",
    "            \n",
    "        # assign matrix to x values    \n",
    "        x[key_set] = np.array(matrix_x)\n",
    "        y[key_set] = np.array(matrix_y)\n",
    "        IDs[key_set] = np.array(matrix_IDs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1045f6-c1f5-4991-ab8c-c6578ef59354",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spectra high vs low protein groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cdf00d-69e4-4948-a856-b2bee09f6f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether length of x and y agrees in each key_set\n",
    "for key_set in x:\n",
    "    print(len(x[key_set]), len(y[key_set])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4661f7b4-290c-4e3c-8b9d-5c6e76f8d8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y['Ag_100nm_AgNPs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88445a78-9db7-46d2-809d-821f58ae2732",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['Ag_100nm_AgNPs'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb38893-c797-4f8c-b2d1-3a5b0a3266ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionaries x_low and x_high\n",
    "x_low = dict.fromkeys( list(x.keys()), [])\n",
    "x_high = dict.fromkeys( list(x.keys()), [] )\n",
    "\n",
    "print(x_low)\n",
    "print(x_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b8edd4-1073-4af1-8450-bf97d186a313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether we have correct keys\n",
    "x.keys() == y.keys() == x_low.keys() == x_high.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432616e-e6a6-4c28-bb32-a73c14f8e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append values to x_low and x_high\n",
    "for key_set in x.keys():\n",
    "    \n",
    "    x_low[key_set] = []\n",
    "    x_high[key_set] = []\n",
    "    \n",
    "    for i in range(len(x[key_set])):\n",
    "        if y[key_set][i] == 0:\n",
    "            x_low[key_set].append(x[key_set][i])\n",
    "        elif y[key_set][i] == 1:\n",
    "            x_high[key_set].append(x[key_set][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b67871-5dc5-4e7b-bbf2-5681246f88f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check \n",
    "for key_set in x:\n",
    "    print(len(x_low[key_set]), len(x_high[key_set]), len(x[key_set]))\n",
    "    print(len(x_low[key_set]) + len(x_high[key_set]) == len(x[key_set]), key_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4f221-92a8-4d5d-8562-eeecd6caabb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_set = 'Ag_100nm_AgNPs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98fbef0-9daf-4edf-ba9d-50a3d26ba182",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_low[key_set][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a9b41-4d60-459c-babd-72567379ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize spectra\n",
    "for key_set in x:\n",
    "    plt.figure(figsize =(16,8))\n",
    "    if key_set != 'Si_60nm_AuNPs' and key_set != 'Si_3x_100nm_AuNPs':\n",
    "        for i in range(len(x_low[key_set])):\n",
    "            plt.subplot(1,2,1)\n",
    "            # print(key_set,len(wave), len(x_low[key_set][i]))\n",
    "            plt.plot(wave, x_low[key_set][i])\n",
    "            plt.xlabel('Raman shift, cm-1')\n",
    "            plt.ylabel('Raman intensity, a.u.')\n",
    "            plt.title(f'{key_set} - low protein')\n",
    "        for i in range(len(x_high[key_set])):\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.plot(wave, x_high[key_set][i])\n",
    "            plt.xlabel('Raman shift, cm-1')\n",
    "            plt.ylabel('Raman intensity, a.u.')\n",
    "            plt.title(f'{key_set} - high protein')\n",
    "        \n",
    "    else:\n",
    "        for i in range(len(x_low[key_set])):\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.plot(wave_Si, x_low[key_set][i])\n",
    "            plt.xlabel('Raman shift, cm-1')\n",
    "            plt.ylabel('Raman intensity, a.u.')\n",
    "            plt.title(f'{key_set} - low protein')\n",
    "        for i in range(len(x_high[key_set])):\n",
    "            plt.subplot(1,2,2)\n",
    "            plt.plot(wave_Si, x_high[key_set][i])\n",
    "            plt.xlabel('Raman shift, cm-1')\n",
    "            plt.ylabel('Raman intensity, a.u.')\n",
    "            plt.title(f'{key_set} - high protein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b08f9a-e1df-422c-93d7-98a717aed6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_low_average = dict.fromkeys( list(x.keys()) , [])\n",
    "x_high_average = dict.fromkeys( list(x.keys()) , [])\n",
    "\n",
    "for key_set in x_low:\n",
    "    \n",
    "    x_low_average[key_set] = []\n",
    "    x_high_average[key_set] = []\n",
    "    \n",
    "    \n",
    "    x_low_average[key_set].append(np.mean(x_low[key_set], axis = 0))\n",
    "    x_high_average[key_set].append(np.mean(x_high[key_set], axis = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f32388b-def6-4b26-ae95-8d222cfe1ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_low_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef20d4bb-b060-487e-9077-6aefefdef524",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_low_average['Ag_100nm_AgNPs'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b391f902-92eb-487d-a5ea-c770aca84ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(x.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c661ef1c-026c-48e4-9a90-36eea44fc19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "\n",
    "for i, key_set in zip([1,2], ['Si_60nm_AuNPs', 'Si_3x_100nm_AuNPs']):\n",
    "    \n",
    "    plt.subplot(1,2,i)\n",
    "    \n",
    "    plt.plot(wave_Si, x_low_average[key_set][0], label = 'low protein')\n",
    "    plt.plot(wave_Si, x_high_average[key_set][0], label = 'high protein')\n",
    "    plt.plot(wave_Si, x_high_average[key_set][0]-x_low_average[key_set][0], label = 'high - low')\n",
    "    plt.xlabel('Raman shift, cm-1')\n",
    "    plt.ylabel('Raman intensity, a.u.')\n",
    "    plt.title(f'{key_set}')\n",
    "\n",
    "    \n",
    "plt.figure(figsize=(16,24))\n",
    "\n",
    "for i, key_set in zip([1,2,3,4,5,6], ['Ag_100nm_AgNPs', 'Ag_100nm_AuNPs', 'Au_60nm_AuNPs', 'Au_100nm_AuNPs','Al_tape_60nm_AuNPs', 'Al_tape_100nm_AuNPs', ]):\n",
    "    \n",
    "    plt.subplot(3,2,i)\n",
    "    \n",
    "    plt.plot(wave, x_low_average[key_set][0], label = 'low protein')\n",
    "    plt.plot(wave, x_high_average[key_set][0], label = 'high protein')\n",
    "    plt.plot(wave, x_high_average[key_set][0]-x_low_average[key_set][0], label = 'high - low')\n",
    "    plt.xlabel('Raman shift, cm-1')\n",
    "    plt.ylabel('Raman intensity, a.u.')\n",
    "    plt.title(f'{key_set}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5626ff7-27c7-4a36-a3bc-fedc8b8f2cc6",
   "metadata": {},
   "source": [
    "## Save x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565d0819-da12-44bd-b158-bfb8cbc2d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_excel = 'processed_urine_spectra_X.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(file_excel)\n",
    "\n",
    "for key_set in x:\n",
    "    \n",
    "    df = pd.DataFrame.from_dict( x[key_set] )\n",
    "    df.to_excel(writer, sheet_name=key_set, header=False, index=False)\n",
    "\n",
    "writer.save()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e406c6-2cdc-4050-b7a6-33e6fec6b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_excel = 'processed_urine_spectra_Y.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(file_excel)\n",
    "\n",
    "for key_set in y:\n",
    "    \n",
    "    df = pd.DataFrame.from_dict( y[key_set] )\n",
    "    df.to_excel(writer, sheet_name=key_set, header=False, index=False)\n",
    "\n",
    "writer.save()\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299d9a02-3575-4dc7-a21d-624b1d1c0594",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5fbe56-b089-46d1-bc60-033d1d3c123a",
   "metadata": {},
   "source": [
    "All metrics will run as dependants of PC components. Exactly as in paper 1. Besides LDA, I will add other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadb667-a76a-4c1b-bd30-34667fd52df6",
   "metadata": {},
   "source": [
    "## PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adccdb8-f192-4cb9-ba02-b1cf9f71436d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# perform PCA analysis on all set\n",
    "pca = PCA(0.999)\n",
    "x_pca = copy.deepcopy(x)\n",
    "for key_set in x.keys():\n",
    "    x_pca[key_set] = pca.fit(x[key_set]).transform(x[key_set]) # xx_pca=pca.fit_transform(x)\n",
    "    print(f'{key_set}' + f' - PCA components {pca.n_components_}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af5343a-8cba-4289-8258-7f291c9bc8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of how to take first 3 PC components\n",
    "x_pca['Ag_100nm_AgNPs'][1][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147d0c9",
   "metadata": {},
   "source": [
    "## Estimators preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4365c6-70d9-4c6b-9187-bb48e66d0c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimators:\n",
    "# LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# RFC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Naive Gaussian\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# create dictionary of models\n",
    "models_dict = {#'LogisticRegression': LogisticRegression(),\n",
    "              'Linear Discriminant Analysis': LinearDiscriminantAnalysis(),\n",
    "               #'Gaussian Naive Bayes': GaussianNB(),\n",
    "              'K-nearest Neighbors': KNeighborsClassifier(n_neighbors=10),\n",
    "              'Support Vector Machnines': SVC()}\n",
    "\n",
    "# create dict of scores that will be overwritten\n",
    "empty_models_dict = copy.deepcopy(models_dict)\n",
    "for key_model in empty_models_dict.keys():\n",
    "    empty_models_dict[key_model] = []\n",
    "\n",
    "# scores dict need to have key_set\n",
    "results_acc_cv = {}\n",
    "results_acc = {}\n",
    "probability_dict = {}\n",
    "probability_dict_cv = {}\n",
    "auc_values = {}\n",
    "auc_values_cv = {}\n",
    "for key_set in x.keys():\n",
    "    results_acc_cv[key_set] = copy.deepcopy(empty_models_dict)\n",
    "    results_acc[key_set] = copy.deepcopy(empty_models_dict)\n",
    "    probability_dict[key_set] = copy.deepcopy(empty_models_dict)\n",
    "    probability_dict_cv[key_set] = copy.deepcopy(empty_models_dict)\n",
    "    auc_values[key_set] = copy.deepcopy(empty_models_dict)\n",
    "    auc_values_cv[key_set] = copy.deepcopy(empty_models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab56b7f-4951-4f8e-8e83-b7bc92424e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how it looks\n",
    "results_acc_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5d80c9-41f3-4a19-a2c0-6d55441c01fc",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dfcaf2-7c23-4b2d-9f12-2d9538f55aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define range for PC components\n",
    "PC_range = np.arange(3,25,2)\n",
    "PC_range =np.append(PC_range, [50, 60, 70])\n",
    "PC_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166fc6dd-21ca-4f3c-8cf1-b46c386b7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training and evaluation on all data points\n",
    "from sklearn import metrics\n",
    "\n",
    "for key_set in results_acc_cv.keys():\n",
    "    \n",
    "    for key_model in results_acc_cv[key_set].keys():\n",
    "        \n",
    "        # cycle through each PC component\n",
    "        for i in PC_range:\n",
    "            \n",
    "            # define some variables\n",
    "            model = models_dict[key_model]\n",
    "            x_ = x_pca[key_set][:,:i]\n",
    "                        \n",
    "            # fit, predict\n",
    "            model.fit(x_, y[key_set])            \n",
    "            y_pred = model.predict(x_)\n",
    "            \n",
    "            acc = metrics.accuracy_score(y[key_set], y_pred)\n",
    "            \n",
    "            acc = round(acc, 4)\n",
    "            \n",
    "            results_acc[key_set][key_model].append(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0fc53-3988-44f4-aec4-c3dd58c0a3d5",
   "metadata": {},
   "source": [
    "## Crossvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23287a-cb1b-40ea-9520-8e4f81464c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore x_pca\n",
    "print(x_pca.keys())\n",
    "print(x_pca['Ag_100nm_AgNPs'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248264e8-281b-44b4-8d1b-cb8420e8ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "K = 10\n",
    "\n",
    "for key_set in results_acc_cv.keys():\n",
    "    \n",
    "    for key_model in results_acc_cv[key_set].keys():\n",
    "        \n",
    "        # cycle through each PC component\n",
    "        for i in PC_range:\n",
    "            # print(key_set, key_model, i)\n",
    "            acc_cv_array = cross_val_score(                \n",
    "                models_dict[key_model],\n",
    "                x_pca[key_set][:,:i], # [:, :3] selects first 3 columns for all arrays\n",
    "                y[key_set],\n",
    "                scoring='accuracy',\n",
    "                cv=K\n",
    "            )\n",
    "            # print(acc_cv_array)\n",
    "            \n",
    "            acc_cv_array = np.round_(acc_cv_array, decimals=4)\n",
    "            \n",
    "            results_acc_cv[key_set][key_model].append([acc_cv_array])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd0a3a-4e01-49c5-ae19-8db58519bc78",
   "metadata": {},
   "source": [
    "## Create means for results_acc_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5595a62d-4533-46e0-9f5f-544d62cfb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc_cv[key_set]['Linear Discriminant Analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ad00c4-d237-4200-9321-26edff5bb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a deepcopy\n",
    "results_acc_mean_cv = copy.deepcopy(results_acc_cv)\n",
    "\n",
    "# calculate results_acc_mean_cv\n",
    "for key_set in results_acc_cv.keys():\n",
    "    \n",
    "    for key_model in results_acc_cv[key_set].keys():\n",
    "        \n",
    "        for i in range( len(results_acc_cv[key_set][key_model]) ):\n",
    "            \n",
    "            results_acc_mean_cv[key_set][key_model][i] = np.mean(results_acc_cv[key_set][key_model][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de1de0-c15d-4973-a13a-e665f482a310",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_acc_mean_cv.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5e96e1-9194-4267-abc5-5f1e0c5a24c4",
   "metadata": {},
   "source": [
    "## Compare accuracies from cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73feb50-6067-46aa-9c27-c96f4a717244",
   "metadata": {},
   "source": [
    "## Visualize tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff1fb28-d68d-40e9-9889-dcb72898df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take example set\n",
    "key_set = 'Ag_100nm_AuNPs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82aff21-41ed-49cb-a734-def3d4edbebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.DataFrame.from_dict(results_acc_mean_cv[key_set])\n",
    "df_cv['PC_score'] = PC_range\n",
    "df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c280e-55aa-4a8e-b573-992a32b01672",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results_acc[key_set])\n",
    "df['PC_score'] = PC_range\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b018b-4007-41bf-b1a7-34d83523c253",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save df tables to excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c74738-29d2-4916-8fff-5f6ad9adc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_excel = 'summary tables ACC.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(file_excel)\n",
    "\n",
    "for key_set in results_acc:\n",
    "    \n",
    "    # no crossvalidation\n",
    "    df = pd.DataFrame.from_dict( results_acc[key_set] )\n",
    "    \n",
    "    # crossvalidation\n",
    "    df_cv = pd.DataFrame.from_dict( results_acc_mean_cv[key_set] )\n",
    "    \n",
    "    # merge\n",
    "    df_merged = pd.concat([df, df_cv], axis =1)\n",
    "    \n",
    "    # insert PC component at the first place\n",
    "    df_merged.insert(0, 'PC_component', PC_range)\n",
    "    \n",
    "    # save to excel\n",
    "    df_merged.to_excel(writer, sheet_name=key_set, index=False)\n",
    "\n",
    "writer.save()\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086a7d9d-7688-464c-aa33-48b429981c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9672e98a-94e8-4754-90ae-e8b77bd1ae68",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8086811d-3f89-4ddf-8605-4e4dee2216d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve for Ag_100nm_AuNPs as it has the best performance\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# plot learning curve \n",
    "\n",
    "key_set = 'Ag_100nm_AuNPs'\n",
    "train_sizes, train_scores, valid_scores = learning_curve(KNeighborsClassifier(), x_pca[key_set], y[key_set], train_sizes = np.linspace(0.1, 1.0, 5), scoring = 'accuracy', cv=int(K))\n",
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "valid_scores_mean = valid_scores.mean(axis = 1)\n",
    "plt.figure(figsize = [15,10])\n",
    "plt.plot(train_sizes, train_scores_mean, \"o--\", label = 'training scores')\n",
    "plt.plot(train_sizes, valid_scores_mean, \"o--\", label = 'validation scores')\n",
    "plt.legend()\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('training size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75780c9-f82d-4363-85c8-c746d0b34c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning curve for Al_tape_60nm_AuNPs as it has the worst performance\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "# plot learning curve \n",
    "\n",
    "key_set = 'Al_tape_60nm_AuNPs'\n",
    "train_sizes, train_scores, valid_scores = learning_curve(KNeighborsClassifier(), x_pca[key_set], y[key_set], train_sizes = np.linspace(0.1, 1.0, 5), scoring = 'accuracy', cv=int(K))\n",
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "valid_scores_mean = valid_scores.mean(axis = 1)\n",
    "plt.figure(figsize = [15,10])\n",
    "plt.plot(train_sizes, train_scores_mean, \"o--\", label = 'training scores')\n",
    "plt.plot(train_sizes, valid_scores_mean, \"o--\", label = 'validation scores')\n",
    "plt.legend()\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('training size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f9bf7-908d-4d41-8615-e1adff44a14e",
   "metadata": {},
   "source": [
    "# Decision boundary plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d573d2e-282c-4add-8d80-c2262ec5f3e1",
   "metadata": {},
   "source": [
    "Plot decision boundaries for PC1 and PC2 with various classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527e640-c91f-4b59-b478-7099de0bb81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict that contains only PC1 and PC2\n",
    "x_pca_2 = {}\n",
    "\n",
    "for key_set in x_pca.keys():\n",
    "    x_pca_2[key_set] = x_pca[key_set][:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329c174-4ae7-48b4-adb9-caa7b9fa0e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_keys = len(x_pca_2.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d646972-ee38-47fc-81cc-47bfa29b5838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# plot PC1 (x-axis) vs PC2 (y-axis)\n",
    "plt.figure(figsize=[20,20])\n",
    "for key_set, index_set in zip(x_pca_2.keys(), np.arange(1,no_keys+1)):\n",
    "    \n",
    "    x_axis = x_pca_2[key_set][:,0]\n",
    "    y_axis = x_pca_2[key_set][:,1]\n",
    "    colors=['red' if l==1 else 'blue' for l in y[key_set]]\n",
    "    \n",
    "#     # run classifier\n",
    "#     classifier = LinearDiscriminantAnalysis().fit(x_pca_2[key_set], y[key_set])\n",
    "    \n",
    "#     disp = DecisionBoundaryDisplay.from_estimator(\n",
    "#         classifier, x_pca_2[key_set], response_method=\"predict\",\n",
    "#         xlabel='PC1', ylabel='PC2',\n",
    "#         alpha=0.5,\n",
    "#     )\n",
    "    \n",
    "#     plt.title(key_set)\n",
    "#     plt.xlim([np.min(x_axis),np.max(x_axis)])\n",
    "#     plt.ylim([np.min(y_axis),np.max(y_axis)])\n",
    "#     plt.figure(figsize=[8,8])\n",
    "    \n",
    "    \n",
    "#     disp.ax_.scatter(x_axis, y_axis, color=colors)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plt.subplot(3,3,index_set)\n",
    "    plt.scatter(x_axis, y_axis, color=colors)\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.title(key_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c62fb11-8cb6-4a0f-b7fa-13d9bc0c14e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9a4201-a68a-4aee-b257-ca8a3e1525d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f1c460-f945-4f7b-a931-146a1c73b4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
